{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWeNcJxybsWe",
        "outputId": "d6809261-a2b0-4ce5-b602-72bb2e9e042f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping cupy-cuda115 as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.6/96.6 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.8/88.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.6/83.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for session-info (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "#@title Installs\n",
        "!pip uninstall cupy-cuda115 -q\n",
        "!pip install cupy-cuda11x -q\n",
        "!pip3 install scanpy[leiden] -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fz-ehDOx4Wpx",
        "outputId": "a5dcf8df-b1cf-48d3-9b51-50eaba29047b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/cupy/_environment.py:540: UserWarning: \n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "  CuPy may not function correctly because multiple CuPy packages are installed\n",
            "  in your environment:\n",
            "\n",
            "    cupy-cuda11x, cupy-cuda12x\n",
            "\n",
            "  Follow these steps to resolve this issue:\n",
            "\n",
            "    1. For all packages listed above, run the following command to remove all\n",
            "       existing CuPy installations:\n",
            "\n",
            "         $ pip uninstall <package_name>\n",
            "\n",
            "      If you previously installed CuPy via conda, also run the following:\n",
            "\n",
            "         $ conda uninstall cupy\n",
            "\n",
            "    2. Install the appropriate CuPy package.\n",
            "       Refer to the Installation Guide for detailed instructions.\n",
            "\n",
            "         https://docs.cupy.dev/en/stable/install.html\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "  warnings.warn(f'''\n"
          ]
        }
      ],
      "source": [
        "#@title Imports and Set Seed\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scanpy as sc\n",
        "import anndata as ad\n",
        "import scipy\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "matplotlib.rcParams['pdf.fonttype']=42\n",
        "\n",
        "from matplotlib import font_manager\n",
        "plt.rcParams['font.size'] = 7\n",
        "\n",
        "import math\n",
        "import random\n",
        "from random import randrange\n",
        "import itertools\n",
        "\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
        "\n",
        "from google.colab import drive # Import if using Google Colab\n",
        "\n",
        "\n",
        "def weight_init_seed(seed):\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "  np.random.seed(seed)\n",
        "  random.seed(seed)\n",
        "\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "\n",
        "weight_init_seed(6631)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEeVKIxr83FW"
      },
      "source": [
        "# Create Pseudobulk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Ya9fXsU889tu",
        "outputId": "5f384a84-bfe9-446d-8f48-21d219ec4a4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/anndata/_core/anndata.py:1758: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
            "  utils.warn_names_duplicates(\"var\")\n",
            "/usr/local/lib/python3.10/dist-packages/anndata/_core/anndata.py:1758: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
            "  utils.warn_names_duplicates(\"var\")\n",
            "/usr/local/lib/python3.10/dist-packages/anndata/_core/anndata.py:1758: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
            "  utils.warn_names_duplicates(\"var\")\n",
            "/usr/local/lib/python3.10/dist-packages/anndata/_core/anndata.py:1758: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
            "  utils.warn_names_duplicates(\"var\")\n",
            "/usr/local/lib/python3.10/dist-packages/anndata/_core/anndata.py:1758: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
            "  utils.warn_names_duplicates(\"var\")\n",
            "/usr/local/lib/python3.10/dist-packages/anndata/_core/anndata.py:1758: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
            "  utils.warn_names_duplicates(\"var\")\n",
            "/usr/local/lib/python3.10/dist-packages/anndata/_core/anndata.py:1758: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
            "  utils.warn_names_duplicates(\"var\")\n"
          ]
        }
      ],
      "source": [
        "# Read in data\n",
        "t0 = sc.read_10x_h5(\"/content/example_data/GSM4504959_E12.5_filtered_gene_bc_matrices.h5\")\n",
        "t1 = sc.read_10x_h5(\"/content/example_data/GSM4504960_E15.5_filtered_gene_bc_matrices.h5\")\n",
        "t2 = sc.read_10x_h5(\"/content/example_data/GSM4504961_E17.5_filtered_gene_bc_matrices.h5\")\n",
        "t3 = sc.read_10x_h5(\"/content/example_data/GSM4504962_P3_filtered_gene_bc_matrices.h5\")\n",
        "t4 = sc.read_10x_h5(\"/content/example_data/GSM4504963_P7_filtered_gene_bc_matrices.h5\")\n",
        "t5 = sc.read_10x_h5(\"/content/example_data/GSM4504964_P15_filtered_gene_bc_matrices.h5\")\n",
        "t6 = sc.read_10x_h5(\"/content/example_data/GSM4504965_P42_filtered_gene_bc_matrices.h5\")\n",
        "\n",
        "# Make variale names unique\n",
        "t0.var_names_make_unique()\n",
        "t1.var_names_make_unique()\n",
        "t2.var_names_make_unique()\n",
        "t3.var_names_make_unique()\n",
        "t4.var_names_make_unique()\n",
        "t5.var_names_make_unique()\n",
        "t6.var_names_make_unique()\n",
        "\n",
        "t0.var['original_index'] = range(len(t0.var))\n",
        "t1.var['original_index'] = range(len(t0.var))\n",
        "t2.var['original_index'] = range(len(t0.var))\n",
        "t3.var['original_index'] = range(len(t0.var))\n",
        "t4.var['original_index'] = range(len(t0.var))\n",
        "t5.var['original_index'] = range(len(t0.var))\n",
        "t6.var['original_index'] = range(len(t0.var))\n",
        "\n",
        "# Filter low quality cells and genes\n",
        "sc.pp.filter_cells(t0, min_genes=100)\n",
        "sc.pp.filter_cells(t1, min_genes=100)\n",
        "sc.pp.filter_cells(t2, min_genes=100)\n",
        "sc.pp.filter_cells(t3, min_genes=100)\n",
        "sc.pp.filter_cells(t4, min_genes=100)\n",
        "sc.pp.filter_cells(t5, min_genes=100)\n",
        "sc.pp.filter_cells(t6, min_genes=100)\n",
        "\n",
        "sc.pp.filter_genes(t0, min_cells=3)\n",
        "sc.pp.filter_genes(t1, min_cells=3)\n",
        "sc.pp.filter_genes(t2, min_cells=3)\n",
        "sc.pp.filter_genes(t3, min_cells=3)\n",
        "sc.pp.filter_genes(t4, min_cells=3)\n",
        "sc.pp.filter_genes(t5, min_cells=3)\n",
        "sc.pp.filter_genes(t6, min_cells=3)\n",
        "\n",
        "h5_files = [t0, t1, t2, t3, t4, t5, t6]\n",
        "pseudo_bulks = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aSo21ui-NdbH"
      },
      "outputs": [],
      "source": [
        "# Find common genes (intersection of .var.index across all time points)\n",
        "common_genes = set(h5_files[0].var.index)\n",
        "for adata in h5_files[1:]:\n",
        "    common_genes.intersection_update(adata.var.index)\n",
        "\n",
        "new_gene_series = t0.var.loc[list(common_genes)]\n",
        "gene_index_list = new_gene_series['original_index'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLecKgxLN_YB",
        "outputId": "8d378f4b-d284-457d-9e54-e21c0b922673"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/anndata/_core/anndata.py:1758: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
            "  utils.warn_names_duplicates(\"var\")\n",
            "/usr/local/lib/python3.10/dist-packages/anndata/_core/anndata.py:1758: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
            "  utils.warn_names_duplicates(\"var\")\n",
            "/usr/local/lib/python3.10/dist-packages/anndata/_core/anndata.py:1758: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
            "  utils.warn_names_duplicates(\"var\")\n",
            "/usr/local/lib/python3.10/dist-packages/anndata/_core/anndata.py:1758: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
            "  utils.warn_names_duplicates(\"var\")\n",
            "/usr/local/lib/python3.10/dist-packages/anndata/_core/anndata.py:1758: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
            "  utils.warn_names_duplicates(\"var\")\n",
            "/usr/local/lib/python3.10/dist-packages/anndata/_core/anndata.py:1758: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
            "  utils.warn_names_duplicates(\"var\")\n",
            "/usr/local/lib/python3.10/dist-packages/anndata/_core/anndata.py:1758: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
            "  utils.warn_names_duplicates(\"var\")\n",
            "/usr/local/lib/python3.10/dist-packages/anndata/_core/anndata.py:1758: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
            "  utils.warn_names_duplicates(\"var\")\n",
            "/usr/local/lib/python3.10/dist-packages/anndata/_core/anndata.py:1758: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
            "  utils.warn_names_duplicates(\"var\")\n",
            "/usr/local/lib/python3.10/dist-packages/anndata/_core/anndata.py:1758: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
            "  utils.warn_names_duplicates(\"var\")\n",
            "/usr/local/lib/python3.10/dist-packages/anndata/_core/anndata.py:1758: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
            "  utils.warn_names_duplicates(\"var\")\n",
            "/usr/local/lib/python3.10/dist-packages/anndata/_core/anndata.py:1758: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
            "  utils.warn_names_duplicates(\"var\")\n",
            "/usr/local/lib/python3.10/dist-packages/anndata/_core/anndata.py:1758: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
            "  utils.warn_names_duplicates(\"var\")\n",
            "/usr/local/lib/python3.10/dist-packages/anndata/_core/anndata.py:1758: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
            "  utils.warn_names_duplicates(\"var\")\n"
          ]
        }
      ],
      "source": [
        "t0 = sc.read_10x_h5(\"/content/example_data/GSM4504959_E12.5_filtered_gene_bc_matrices.h5\")\n",
        "t1 = sc.read_10x_h5(\"/content/example_data/GSM4504960_E15.5_filtered_gene_bc_matrices.h5\")\n",
        "t2 = sc.read_10x_h5(\"/content/example_data/GSM4504961_E17.5_filtered_gene_bc_matrices.h5\")\n",
        "t3 = sc.read_10x_h5(\"/content/example_data/GSM4504962_P3_filtered_gene_bc_matrices.h5\")\n",
        "t4 = sc.read_10x_h5(\"/content/example_data/GSM4504963_P7_filtered_gene_bc_matrices.h5\")\n",
        "t5 = sc.read_10x_h5(\"/content/example_data/GSM4504964_P15_filtered_gene_bc_matrices.h5\")\n",
        "t6 = sc.read_10x_h5(\"/content/example_data/GSM4504965_P42_filtered_gene_bc_matrices.h5\")\n",
        "\n",
        "t0.var['original_index'] = range(len(t0.var))\n",
        "t1.var['original_index'] = range(len(t0.var))\n",
        "t2.var['original_index'] = range(len(t0.var))\n",
        "t3.var['original_index'] = range(len(t0.var))\n",
        "t4.var['original_index'] = range(len(t0.var))\n",
        "t5.var['original_index'] = range(len(t0.var))\n",
        "t6.var['original_index'] = range(len(t0.var))\n",
        "\n",
        "sc.pp.filter_cells(t0, min_genes=100)\n",
        "sc.pp.filter_cells(t1, min_genes=100)\n",
        "sc.pp.filter_cells(t2, min_genes=100)\n",
        "sc.pp.filter_cells(t3, min_genes=100)\n",
        "sc.pp.filter_cells(t4, min_genes=100)\n",
        "sc.pp.filter_cells(t5, min_genes=100)\n",
        "sc.pp.filter_cells(t6, min_genes=100)\n",
        "\n",
        "t0.var_names_make_unique()\n",
        "t1.var_names_make_unique()\n",
        "t2.var_names_make_unique()\n",
        "t3.var_names_make_unique()\n",
        "t4.var_names_make_unique()\n",
        "t5.var_names_make_unique()\n",
        "t6.var_names_make_unique()\n",
        "\n",
        "old_h5_files = [t0, t1, t2, t3, t4, t5, t6]\n",
        "h5_files = []\n",
        "copies = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dqx6oQwORch",
        "outputId": "24ccc62e-b1ba-49b9-ed6a-9b0a7f09080d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/anndata/_core/storage.py:39: ImplicitModificationWarning: X should not be a np.matrix, use np.ndarray instead.\n",
            "  warnings.warn(msg, ImplicitModificationWarning)\n"
          ]
        }
      ],
      "source": [
        "# Make new AnnData objects with common genes\n",
        "for ti in old_h5_files:\n",
        "  filtered_X = ti.X.todense()[:, gene_index_list]\n",
        "\n",
        "  new_adata = ad.AnnData(filtered_X, obs=ti.obs, var=new_gene_series)\n",
        "\n",
        "  h5_files.append(new_adata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "yOLdME9IPli1"
      },
      "outputs": [],
      "source": [
        "t0, t1, t2, t3, t4, t5, t6 = h5_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "yyeY5xzXq6yJ"
      },
      "outputs": [],
      "source": [
        "def pseudo_bulk(h5_file):\n",
        "  '''\n",
        "  Converts single-cell RNA-seq data from an h5 file to pseudobulk data. This function:\n",
        "\n",
        "    1. Normalizes each cell's gene expression to a total sum of 10,000.\n",
        "    2. Sets expression values below 10 to zero, reducing noise.\n",
        "    3. Normalizes again to adjust the total expression sum post-thresholding.\n",
        "    4. Computes the average expression across all cells for each gene.\n",
        "    5. Applies a log transformation (log1p) to the averaged values.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  h5_file\n",
        "      An AnnData object containing single-cell RNA-seq data.\n",
        "\n",
        "  Returns\n",
        "  ----------\n",
        "  pseudobulk_h5_file\n",
        "      A numpy array containing log-transformed average gene expression values for pseudobulk data.\n",
        "  '''\n",
        "  sc.pp.normalize_total(h5_file, target_sum=1e4)  # Normalize single-cell data\n",
        "\n",
        "  h5_file.X[h5_file.X < 10] = 0  # Threshold at < 10\n",
        "\n",
        "  sc.pp.normalize_total(h5_file, target_sum=1e4) # Normalize again\n",
        "\n",
        "  pseudobulk_h5_file = np.asarray(h5_file.X.mean(axis=0)).flatten() # Avg\n",
        "\n",
        "  pseudobulk_h5_file = np.log1p(pseudobulk_h5_file) # Log1p\n",
        "\n",
        "  return pseudobulk_h5_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "V-8wHc-Rjzcp"
      },
      "outputs": [],
      "source": [
        "def create_pseudo_bulk(h5_files):\n",
        "  '''\n",
        "  Generates pseudobulk from all time-stamps\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  h5_file\n",
        "      An AnnData object containing single-cell RNA-seq data.\n",
        "\n",
        "  Returns\n",
        "  ----------\n",
        "  np.array\n",
        "      Pseuobulk data from all time-stamps.\n",
        "  '''\n",
        "  pseudo_bulks = []\n",
        "  for h5_file in h5_files:\n",
        "    pseudo_h5 = pseudo_bulk(h5_file)\n",
        "    pseudo_bulks.append(pseudo_h5)\n",
        "\n",
        "  return np.array(pseudo_bulks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "TO79M0F1-Wly"
      },
      "outputs": [],
      "source": [
        "obs_names = {} # For .obs of bulk AnnData object\n",
        "for i in range(len(h5_files)): # 7\n",
        "  obs_names[i] = \"TimeStamp\" + str(i)\n",
        "obs_frame = pd.DataFrame(list(obs_names.items()), columns=['Index', 'TimeStamp'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gf1BMXxjDCJv",
        "outputId": "5e5a7b75-988f-40a4-a9e7-fd309b09bccf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/anndata/_core/aligned_df.py:68: ImplicitModificationWarning: Transforming to str index.\n",
            "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"
          ]
        }
      ],
      "source": [
        "# Create bulk object\n",
        "bulks = create_pseudo_bulk(h5_files)\n",
        "bulks_adata = ad.AnnData(bulks, obs=obs_frame, var=h5_files[0].var)\n",
        "sc.pp.highly_variable_genes(bulks_adata, n_top_genes=6000, subset=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "spQOEKGWx9RK"
      },
      "outputs": [],
      "source": [
        "# Add names of files\n",
        "bulks_adata.obs['files'] = ['GSM4504959_E12.5_filtered_gene_bc_matrices.h5', 'GSM4504960_E15.5_filtered_gene_bc_matrices.h5',\n",
        "                            'GSM4504961_E17.5_filtered_gene_bc_matrices.h5', 'GSM4504962_P3_filtered_gene_bc_matrices.h5',\n",
        "                            'GSM4504963_P7_filtered_gene_bc_matrices.h5', 'GSM4504964_P15_filtered_gene_bc_matrices.h5',\n",
        "                            'GSM4504965_P42_filtered_gene_bc_matrices.h5']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "oqE3EWhCW0P0"
      },
      "outputs": [],
      "source": [
        "def pick_gene(gene_no, gene_database=bulks_adata):\n",
        "  \"\"\"\n",
        "  Selects and returns expression data for a specific gene across all samples from a gene database.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  gene_no\n",
        "      The index of the gene in the gene database.\n",
        "  gene_database\n",
        "      An AnnData object containing gene expression data. The default is `bulks_adata`.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  numpy.ndarray\n",
        "      An array containing the expression values for the specified gene across all time points.\n",
        "\n",
        "  \"\"\"\n",
        "  return gene_database.X[:, gene_no]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "iq8VLu3LRXDR"
      },
      "outputs": [],
      "source": [
        "# Look at time series patterns of a selected gene\n",
        "gene_timeseries = pick_gene(0)\n",
        "def plot_geneseries(gene):\n",
        "  length = [x for x in range(len(gene))]\n",
        "  plt.plot(length, gene)\n",
        "  plt.xlabel('Time')\n",
        "  plt.ylabel('Gene Expression')\n",
        "\n",
        "# plot_geneseries(gene_timeseries)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Obrg0jI4jTEQ"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hQlEDawFT7-"
      },
      "source": [
        "### KNN Function\n",
        "Find neighboring genes\n",
        "\n",
        "[Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "YcI5weWpjUlp"
      },
      "outputs": [],
      "source": [
        "k = 15\n",
        "k += 1\n",
        "neighbors = NearestNeighbors(n_neighbors=k) # k = x, x-1 neighbors\n",
        "neighbors.fit(bulks_adata.X.T)\n",
        "\n",
        "def find_neighbors(g, neighbors_func=neighbors, gene_database=bulks_adata):\n",
        "  \"\"\"\n",
        "  Finds and returns the indices of the nearest neighbors for a given gene vector in the gene database.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  g\n",
        "      The gene vector for which neighbors are to be found\n",
        "  neighbors_func\n",
        "      A fitted NearestNeighbors object from scikit-learn.\n",
        "      The default is `neighbors`, which should be predefined as a NearestNeighbors object.\n",
        "  gene_database\n",
        "      An AnnData object containing gene expression data. The default is `bulks_adata`.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  numpy.ndarray\n",
        "      An array of indices for the nearest neighbors, excluding the index of the gene vector itself.\n",
        "\n",
        "  Notes\n",
        "  -----\n",
        "  The function assumes `neighbors_func` has been fitted to the gene expression data in `gene_database`.\n",
        "  Ensure `neighbors_func` is appropriately initialized and fitted outside of this function.\n",
        "\n",
        "  \"\"\"\n",
        "  neighbor_arr = neighbors_func.kneighbors([g])\n",
        "  return neighbor_arr[1][0][1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "TYh_ReuzYhfJ",
        "outputId": "e7e3889e-144b-463f-9386-48ee24a0ce56"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Check, do the time series looks similar?\n",
        "gene_0 = pick_gene(0)\n",
        "gene0_neighbors = find_neighbors(gene_0)\n",
        "plot_geneseries(pick_gene(gene0_neighbors[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUuDLbdo1454"
      },
      "source": [
        "### Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "collapsed": true,
        "id": "lB73mZ5CcA0y"
      },
      "outputs": [],
      "source": [
        "# Format input for NN\n",
        "def format_input(g, gene_database=bulks_adata):\n",
        "  \"\"\"\n",
        "  format_input formats the input for the NN. Shape to format: [g1,...,gt,n1,...,nt]\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  g\n",
        "    Gene expression values across all time points for single gene g\n",
        "  gene_database\n",
        "    Database to pull gene expressions from\n",
        "\n",
        "  Retuens\n",
        "  ----------\n",
        "  input\n",
        "    Formatted input, with genes and neighbors as features\n",
        "  \"\"\"\n",
        "  neighbors = find_neighbors(g, gene_database=gene_database) # Get indices of all neighbors of g\n",
        "  input = np.array(g)\n",
        "\n",
        "  for n in neighbors:\n",
        "    neighbor_gene = np.array(pick_gene(n))\n",
        "    input = np.concatenate((input, neighbor_gene), axis=None) # Concat neighbors with original gene\n",
        "\n",
        "  return input\n",
        "\n",
        "# gene0 = format_input(pick_gene(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "cefF_f7wFo5A"
      },
      "outputs": [],
      "source": [
        "all_inputs = [] # All inputs, formatted, not scaled\n",
        "\n",
        "time_embeddings = [x for x in range(bulks_adata.obs.shape[0])]\n",
        "\n",
        "for i in range( int(len(bulks_adata.var)) ):\n",
        "  # Pick gene and format the input\n",
        "  gene_i = pick_gene(i)\n",
        "  formatted_input = format_input(gene_i)\n",
        "\n",
        "  all_inputs.append(formatted_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "VWdRwS30TiUq"
      },
      "outputs": [],
      "source": [
        "# Masking mechanism\n",
        "def mask(time_points, input, mask_value=np.NINF, gene_database=bulks_adata):\n",
        "    \"\"\"\n",
        "    Masks specified time points in the input array with a given mask value and returns the modified array along with the original values at the masked positions.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    time_points\n",
        "        Indices of the time points to be masked in the input array. Assumes 0-based indexing.\n",
        "    input\n",
        "        The array containing values to be masked.\n",
        "    mask_value\n",
        "        The value used to replace the entries at the specified time points. Default is np.NINF (negative infinity).\n",
        "    gene_database\n",
        "        An AnnData object containing gene expression data. This is not directly used in the function but included for potential extensions. Default is `bulks_adata`.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    tuple\n",
        "        A tuple containing two elements:\n",
        "        1. The modified input array with specific time points replaced by `mask_value`.\n",
        "        2. An array of the original values at the masked positions.\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> input_array = np.array([10, 20, 30, 40, 50])\n",
        "    >>> time_points_to_mask = [1, 3]\n",
        "    >>> masked_array, original_values = mask(time_points_to_mask, input_array)\n",
        "    >>> masked_array\n",
        "    array([10, -inf, 30, -inf, 50])\n",
        "    >>> original_values\n",
        "    array([20, 40])\n",
        "    \"\"\"\n",
        "    new_arr = input.copy()\n",
        "    max_timepoints = bulks_adata.obs.shape[0]\n",
        "    masked = []\n",
        "\n",
        "    first_y = []\n",
        "\n",
        "    for n in range(len(input)):\n",
        "      ts_mask = n % max_timepoints\n",
        "\n",
        "      if ts_mask in time_points: # Mask each time-point for every neighbour\n",
        "        masked.append(new_arr[n])\n",
        "\n",
        "        if ts_mask == time_points[0]:\n",
        "          first_y.append(new_arr[n])\n",
        "\n",
        "        new_arr[n] = mask_value  # Masked with -inf by default\n",
        "\n",
        "    new_arr = np.append(new_arr, time_points[0])\n",
        "\n",
        "    return new_arr, first_y\n",
        "\n",
        "# test, masked = mask([2, 1, 3], gene0)\n",
        "# print(gene0)\n",
        "# print(test, masked)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "s7CQWvVzoRCF"
      },
      "outputs": [],
      "source": [
        "time_embeddings=[0, 1, 2, 3, 4, 5, 6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "4b8WHQO8LSWx"
      },
      "outputs": [],
      "source": [
        "X_train_note, X_test_note = train_test_split(all_inputs, train_size=0.8, shuffle=True) # 80/20 Split all inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "hGVPvGB7Icvv"
      },
      "outputs": [],
      "source": [
        "all_data = [] # Append time embeddings\n",
        "for i in range(len(X_train_note)):\n",
        "  all_data.append( np.append(X_train_note[i], time_embeddings) )\n",
        "\n",
        "for i in range( len(X_test_note) ):\n",
        "  all_data.append( np.append(X_test_note[i], time_embeddings) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "YNxpuGRLnVyy"
      },
      "outputs": [],
      "source": [
        "X_train = []\n",
        "X_test = []\n",
        "\n",
        "for i in range(int(len(all_data) * 0.8)): # 80%, 20% split\n",
        "  X_train.append( all_data[i] )\n",
        "\n",
        "for i in range(int(len(all_data) * 0.8)+1, len(all_data)):\n",
        "  X_test.append( all_data[i] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "2fa-fBw0Ewxu"
      },
      "outputs": [],
      "source": [
        "def generate_combintations(n, time_points=time_embeddings):\n",
        "  \"\"\"\n",
        "    Generates combinations of time point indices where the first element is to be predicted and the rest are masked.\n",
        "    This function creates permutations of the time points, prioritizing the position of the first element in each combination.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    n\n",
        "        The number of time points to include in each combination.\n",
        "    time_points\n",
        "        An array of time point indices available for masking and prediction. The default is `time_embeddings`, which\n",
        "        should be predefined.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    list of tuples\n",
        "        A list of combinations, each as a tuple, where the first element of each tuple is the time point to be predicted (and masked),\n",
        "        and the remaining elements are time points to be masked.\n",
        "  \"\"\"\n",
        "  combinations = []\n",
        "  to_skip = int(math.factorial(n-1))-1 # Want only permutations where first number is different, skip the rest\n",
        "  skipped = to_skip\n",
        "\n",
        "  for comb in itertools.combinations(time_points, n): # Generate combinations of length n\n",
        "    to_avg = [] # Group together permutations that will be averaged in the end\n",
        "\n",
        "    for permutation in list(itertools.permutations(comb)): # Generate permutations of those combinations\n",
        "      if skipped > 0: # Dont want all permutations\n",
        "        skipped -= 1\n",
        "        continue\n",
        "\n",
        "      to_avg.append(list(permutation))\n",
        "\n",
        "      skipped = to_skip\n",
        "\n",
        "    combinations.append(to_avg)\n",
        "\n",
        "    # e.g. combinations[0] has lists of size n. Caluclate MAE for predictions of all of them, take average.\n",
        "\n",
        "  return combinations\n",
        "# generate_combintations(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "7_zDbCtgx2uw"
      },
      "outputs": [],
      "source": [
        "def gen_loader(X_train, n):\n",
        "  \"\"\"\n",
        "  Generates a loader containing training batches for a regressor neural network. Each batch\n",
        "  consists of combinations of data points from the training set, where certain points are masked\n",
        "  according to specified combinations. This function iterates over the training data, applies\n",
        "  masking, and constructs batches suitable for regression training.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  X_train\n",
        "      The input training data from which to generate combinations and batches.\n",
        "  n\n",
        "      The number of elements in each combination, dictating the structure of the masking.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  list of list of tuples\n",
        "      A nested list where each inner list contains tuples of masked data and corresponding target values.\n",
        "      Each tuple represents a training example consisting of a tensor of masked inputs and a tensor of targets.\n",
        "  \"\"\"\n",
        "  X_train_loader = []\n",
        "  i = 0\n",
        "  while i < len(X_train)-1:\n",
        "\n",
        "    for comb in generate_combintations(n):\n",
        "      loader = []\n",
        "      for seq in comb:\n",
        "\n",
        "        if i > len(X_train)-1:\n",
        "          break\n",
        "\n",
        "        masked, y = mask(seq, X_train[i])\n",
        "        masked, y = torch.tensor(masked, dtype=torch.float32), torch.tensor(y[0], dtype=torch.float32)\n",
        "        arr = [masked, y]\n",
        "\n",
        "        loader.append(arr)\n",
        "\n",
        "      X_train_loader.append(loader)\n",
        "      i += 1\n",
        "\n",
        "  return X_train_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "RNFhVYPh1I0x"
      },
      "outputs": [],
      "source": [
        "# Initialize empty lists for different loaders\n",
        "X_train_loader = []\n",
        "AE_train_loader = []\n",
        "AE_test_loader = []\n",
        "\n",
        "# Iterate over each time point\n",
        "for i in range(1, len(time_embeddings)):\n",
        "  random.shuffle(X_train)\n",
        "  gen_i = gen_loader(X_train, i)\n",
        "\n",
        "  X_train_loader.extend( gen_i )\n",
        "\n",
        "  random.shuffle(gen_i)\n",
        "\n",
        "  for j in gen_i[:len(gen_i)//2]:\n",
        "    AE_train_loader.extend( j )\n",
        "\n",
        "  random.shuffle(X_test)\n",
        "  gen_i_test = gen_loader(X_test, i)\n",
        "  random.shuffle(gen_i_test)\n",
        "\n",
        "  for t in gen_i_test:\n",
        "    AE_test_loader.extend( t )\n",
        "\n",
        "random.shuffle(X_train_loader)\n",
        "random.shuffle(AE_train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "tb7k-gfN_b0e"
      },
      "outputs": [],
      "source": [
        "class GeneDatasetAE(torch.utils.data.Dataset):\n",
        "  # Characterizes a dataset for PyTorch\n",
        "  def __init__(self, X):\n",
        "        self.X = X\n",
        "\n",
        "  def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "        # Generates one sample of data\n",
        "        gene = self.X[index]\n",
        "\n",
        "        return gene"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "i0FLXUTq_djo"
      },
      "outputs": [],
      "source": [
        "AEgeneTrainSet = GeneDatasetAE(AE_train_loader)\n",
        "AE_train_loader_x = DataLoader(AEgeneTrainSet, shuffle=True, batch_size=3)\n",
        "\n",
        "AEgeneTestSet = GeneDatasetAE(AE_train_loader)\n",
        "AE_test_loader_X = DataLoader(AEgeneTestSet, shuffle=True, batch_size=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWo2TVkPpq4-"
      },
      "source": [
        "### AutoEncoder + NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "7BByg5dKpt-o"
      },
      "outputs": [],
      "source": [
        "class HybridNN(nn.Module):\n",
        "  # Class for hybrid NN model\n",
        "  def __init__(self, input_size, output_size):\n",
        "      super().__init__()\n",
        "      self.encoder = nn.Sequential(\n",
        "          nn.Linear(input_size, 128),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(128, output_size),\n",
        "      )\n",
        "\n",
        "      self.decoder = nn.Sequential(\n",
        "          nn.Linear(output_size, 128),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(128, input_size),\n",
        "          nn.ReLU()\n",
        "      )\n",
        "\n",
        "      self.regressor = nn.Sequential(\n",
        "          nn.Linear(output_size, 64),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(64, 32),\n",
        "          nn.ReLU(),\n",
        "          nn.Dropout(0.2),\n",
        "          nn.Linear(32, 1),\n",
        "          nn.ReLU()\n",
        "      )\n",
        "\n",
        "  def forward(self, x):\n",
        "      # AutoEncoder\n",
        "      z = self.encoder(x)\n",
        "      decoded = self.decoder(z)\n",
        "\n",
        "      # Regressor NN\n",
        "      regression = self.regressor(z)\n",
        "\n",
        "      return decoded, regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "uobdvNmuy2aj"
      },
      "outputs": [],
      "source": [
        "def custom_loss(y_pred, y, loss_fn):\n",
        "  \"\"\"\n",
        "  Skip over masked values in the calculation. This is done for AE phase\n",
        "  \"\"\"\n",
        "  mask = ~torch.isinf(y) # True if not infinity\n",
        "  return loss_fn(y_pred[mask], y[mask])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "b0BS-biARKB0"
      },
      "outputs": [],
      "source": [
        "dim_reduction_size = 64\n",
        "hybrid_model = HybridNN((k+1) * len(time_embeddings) + 1, dim_reduction_size)\n",
        "\n",
        "loss_MSE = nn.MSELoss() # For AutoEncoder\n",
        "loss_MAE = nn.L1Loss(reduction='none') # For Regressor\n",
        "\n",
        "# Stage 1: AE\n",
        "optimizer_enc = optim.Adam(hybrid_model.encoder.parameters(), lr=0.001, weight_decay=0.0001) # Adam optimizer with learning rate 0.001, weight decay of 0.0001\n",
        "optimizer_dec = optim.Adam(hybrid_model.decoder.parameters(), lr=0.001, weight_decay=0.0001)\n",
        "\n",
        "# Stage 2: Regressor\n",
        "optimizer_reg = optim.SGD(hybrid_model.regressor.parameters(), lr=0.001, momentum=0.9) # SGD optimizer with learning rate 0.001, momentum of 0.9\n",
        "scheduler_reg = optim.lr_scheduler.ExponentialLR(optimizer_reg, gamma=0.9)\n",
        "\n",
        "# Stage 3: Both\n",
        "optimizer_both = optim.SGD(hybrid_model.parameters(), lr=0.0001, momentum=0.9) # Decrease learning rate when training in stage 3\n",
        "scheduler_both = optim.lr_scheduler.ExponentialLR(optimizer_both, gamma=0.9)\n",
        "\n",
        "optimizers = [optimizer_enc, optimizer_dec, optimizer_reg, optimizer_both]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "H-CI_lKFVJus"
      },
      "outputs": [],
      "source": [
        "def train_hybridNN_0mask(hyb_model, loader1, loader2, optimizers, loss_fn1, loss_fn2, custom_loss, epochs):\n",
        "  \"\"\"\n",
        "  Trains a hybrid neural network model in three distinct phases to optimize different components of the model.\n",
        "  Each phase targets a specific part of the model with adapted learning objectives and potentially different learning rates.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  hyb_model\n",
        "      The hybrid neural network model to be trained.\n",
        "  loader1\n",
        "      The data loader containing training data used in training the autoencoder\n",
        "  loader2\n",
        "      The data loader containing training data used in training the regressor\n",
        "  optimizers\n",
        "      A list of PyTorch optimizers for different parts of the model\n",
        "  loss_fn1\n",
        "      The loss function used for the autoencoder training\n",
        "  loss_fn2\n",
        "      The loss function used for the regressor\n",
        "  custom_loss\n",
        "      The combined loss function used when training the autoencoder\n",
        "  epochs\n",
        "      Total number of epochs over which the model is trained across all phases.\n",
        "\n",
        "  Steps\n",
        "  -----\n",
        "  Train model in 3 phases:\n",
        "  1. AutoEncoder\n",
        "  2. Regressor\n",
        "  3. Both\n",
        "\n",
        "  Learning rate is decreased in phase 3. Each stage is trained for `epochs` times.\n",
        "  \"\"\"\n",
        "  optimizer_enc, optimizer_dec, optimizer_reg, optimizer_both = optimizers\n",
        "\n",
        "  epoch_vals = []\n",
        "  loss_vals = []\n",
        "\n",
        "  print(\"AutoEncoder:\")\n",
        "\n",
        "  # -------- Stage 1 --------\n",
        "  # AutoEncoder Part:\n",
        "  for epoch in range(epochs):\n",
        "    hyb_model.train()\n",
        "    last_loss = 0\n",
        "\n",
        "    for AE_input, _ in loader1:\n",
        "      masked_X = torch.nan_to_num(AE_input, nan=0.0, neginf=0.0) # Make all -inf to 0 for forward pass\n",
        "      reconstructed, _ = hyb_model(masked_X)\n",
        "\n",
        "      loss = custom_loss(reconstructed, AE_input, loss_fn1) # Calculate MSE only for non-masked values\n",
        "\n",
        "      optimizer_enc.zero_grad()\n",
        "      optimizer_dec.zero_grad()\n",
        "\n",
        "      loss.backward()\n",
        "\n",
        "      clipping_value = 10\n",
        "      torch.nn.utils.clip_grad_norm_(hyb_model.parameters(), clipping_value)\n",
        "\n",
        "      optimizer_enc.step()\n",
        "      optimizer_dec.step()\n",
        "\n",
        "      last_loss = loss.item()\n",
        "\n",
        "    print(f'Epoch {epoch}: Loss = {last_loss}')\n",
        "\n",
        "  print()\n",
        "  print(\"Regressor:\")\n",
        "\n",
        "  # -------- Stage 2 --------\n",
        "  for epoch in range(epochs):\n",
        "    hyb_model.train()\n",
        "\n",
        "    # Freeze AE\n",
        "    for name, param in hyb_model.named_parameters():\n",
        "      if \"encoder\" in name or \"decoder\" in name:\n",
        "        param.requires_grad = False\n",
        "\n",
        "    last_loss = 0\n",
        "\n",
        "    # Regressor Part:\n",
        "\n",
        "    for batch in loader2:\n",
        "      if batch == []:\n",
        "        continue\n",
        "\n",
        "      avg_loss = 0\n",
        "      optimizer_reg.zero_grad()\n",
        "\n",
        "      for x, y in batch:\n",
        "        masked_X = torch.nan_to_num(x, nan=0.0, neginf=0.0)\n",
        "        _, y_pred = hyb_model(masked_X)\n",
        "\n",
        "        loss = loss_fn2(y_pred, y)\n",
        "        avg_loss += loss/len(batch)\n",
        "\n",
        "      avg_loss.backward()\n",
        "\n",
        "      optimizer_reg.step()\n",
        "      last_loss = avg_loss.item()\n",
        "\n",
        "    scheduler_reg.step()\n",
        "    print(f'Epoch {epoch}: Loss = {last_loss}')\n",
        "\n",
        "  print()\n",
        "  print(\"Both:\")\n",
        "\n",
        "  # -------- Stage 3 --------\n",
        "  for epoch in range(epochs):\n",
        "    hyb_model.train()\n",
        "\n",
        "    # Unfreeze AE\n",
        "    for name, param in hyb_model.named_parameters():\n",
        "      if \"encoder\" in name or \"decoder\" in name:\n",
        "        param.requires_grad = True\n",
        "\n",
        "    for batch in loader2:\n",
        "      if batch == []:\n",
        "        continue\n",
        "\n",
        "      avg_loss_reg = 0\n",
        "      avg_loss_ae = 0\n",
        "\n",
        "      optimizer_both.zero_grad()\n",
        "\n",
        "      for x, y in batch:\n",
        "        masked_X = torch.nan_to_num(x, nan=0.0, neginf=0.0)\n",
        "        reconstruction, y_pred = hyb_model(masked_X)\n",
        "\n",
        "        loss_reg = loss_fn2(y_pred, y)\n",
        "        avg_loss_reg += loss_reg/len(batch)\n",
        "\n",
        "        loss_ae = custom_loss(reconstruction, x, loss_fn1)\n",
        "        avg_loss_ae += loss_ae/len(batch)\n",
        "\n",
        "      combined_loss = avg_loss_reg + avg_loss_ae\n",
        "      combined_loss.backward()\n",
        "\n",
        "      # optimizer.step()\n",
        "      optimizer_both.step()\n",
        "      last_loss = combined_loss.item()\n",
        "\n",
        "    scheduler_both.step()\n",
        "\n",
        "    print(f'Epoch {epoch}: Loss = {last_loss}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_hybridNN_0mask(hybrid_model, AE_train_loader_x, X_train_loader, optimizers, loss_MSE, loss_MAE, custom_loss, epochs=15)"
      ],
      "metadata": {
        "id": "Gm-H2vss5Vfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "SqPkNPeLv0ks"
      },
      "outputs": [],
      "source": [
        "torch.save(hybrid_model.state_dict(), \"hybrid_model.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzDBO4CUJA1d"
      },
      "outputs": [],
      "source": [
        "# Code to load pretrained model\n",
        "# hybrid_model = HybridNN((k+1) * len(time_embeddings) + 1, dim_reduction_size)\n",
        "# hybrid_model.load_state_dict(torch.load(\"hybrid_model.pth\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHQo2OSKKrSg"
      },
      "source": [
        "# Measuring Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MAE and $R^{2}$ model analysis"
      ],
      "metadata": {
        "id": "3UQs7CaW6f59"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "Jl44DxaPPbk5"
      },
      "outputs": [],
      "source": [
        "def MAE(pred, y):\n",
        "  \"\"\"\n",
        "  Maen Absolute Error loss\n",
        "  \"\"\"\n",
        "  return abs(pred-y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "yGDsqheDaVtX"
      },
      "outputs": [],
      "source": [
        "def metric_combinationTS(gene_no, metric_func, n, database=all_data, model=hybrid_model, time_points=time_embeddings, printB=False):\n",
        "  \"\"\"\n",
        "  metric_combinationTS calculate performance metric for prediction of combinations hidden time points for single gene in database.\n",
        "  Prints time points to select for further single cell analysis.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  time_points\n",
        "      How many time points to measure\n",
        "  metric_func\n",
        "      Metric function to measure performance (MAE is preferred)\n",
        "  n\n",
        "      Length of combinations\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  metric_values\n",
        "      Average value of metric for each hidden time point for all genes\n",
        "  \"\"\"\n",
        "\n",
        "  model.eval()\n",
        "  gene = database[gene_no]\n",
        "  max_TS = int(gene[-1])+1\n",
        "\n",
        "  combinations = generate_combintations(n)\n",
        "\n",
        "  metric_values = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for comb in combinations: # Sequence of combinations to average\n",
        "      combintation_sum = 0 # Sum absolute error of all combinations, then divide by n\n",
        "      seed = random.random()\n",
        "\n",
        "      for sequence in comb: # Calculate MAE for each sequence, average them\n",
        "        masked, y = mask(sequence, gene)\n",
        "        masked, y = torch.tensor(masked, dtype=torch.float32), torch.tensor(y[0], dtype=torch.float32)\n",
        "\n",
        "        zeros_X = torch.nan_to_num(masked, nan=0.0, neginf=0.0)\n",
        "        _, prediction = model(zeros_X)\n",
        "\n",
        "        metric_measure = metric_func(prediction, y)[0].item() # Measure error using metric_func\n",
        "        combintation_sum += metric_measure\n",
        "\n",
        "      avg_combination = combintation_sum/n\n",
        "      metric_values.append(avg_combination) # Append value of error\n",
        "\n",
        "      if printB: print(f'{metric_func.__name__} for time point(s) {comb[0]}: {avg_combination}') # Print error value for each time point(s)\n",
        "\n",
        "  metric_values = np.array(metric_values)\n",
        "\n",
        "  if printB:\n",
        "    print(f'Average {metric_func.__name__}: {metric_values.sum()/len(metric_values)}') # Print average value for all time points\n",
        "\n",
        "    lowest_MAE = combinations[metric_values.argmin()][0]\n",
        "    print(f'Lowest time point(s): {lowest_MAE}')\n",
        "\n",
        "  return metric_values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vdfLpmmF0hV"
      },
      "outputs": [],
      "source": [
        "# ar_24002 = metric_combinationTS(24002, MAE, 2, printB=True) # For one gene"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "9KBmoD7RbtEC"
      },
      "outputs": [],
      "source": [
        "def avg_metric_combinationTS(metric_func, n, model, time_points=len(bulks_adata.obs), database=all_data, number_genes=len(bulks_adata.var), verbose=False):\n",
        "  \"\"\"\n",
        "  avg_metric_combinationTS calculate average performance metric for prediction of combinations hidden time points for every gene in database\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  time_points\n",
        "      How many time points to measure\n",
        "  metric_func\n",
        "      Metric function to measure performance (MAE is preferred)\n",
        "  n\n",
        "      How many time points to mask\n",
        "  database\n",
        "      Database to choose genes from\n",
        "  number_genes\n",
        "      Total number of genes\n",
        "  verbose\n",
        "      Print verbose output, otherwise only shows time points to choose for further analysis\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "    avg_val\n",
        "      Array of average value of metric for each hidden time point for all genes\n",
        "    avg_allTS\n",
        "      Average value of metric for all genes\n",
        "  \"\"\"\n",
        "  TS_combinations = generate_combintations(n)\n",
        "  avg_val = np.zeros(len(TS_combinations))\n",
        "\n",
        "  for i in range(number_genes):\n",
        "    vals = metric_combinationTS(i, metric_func, n, model=model, database=database, printB=False)\n",
        "    avg_val += vals\n",
        "\n",
        "  avg_val = avg_val/number_genes\n",
        "  avg_allTS = 0\n",
        "\n",
        "  for t in range(len(avg_val)):\n",
        "    avg_allTS += avg_val[t]\n",
        "    print(f'Average {metric_func.__name__} value for all genes at time point {TS_combinations[t][0]}: {avg_val[t]}')\n",
        "\n",
        "  avg_allTS = avg_allTS/len(avg_val)\n",
        "\n",
        "  if verbose:\n",
        "    print()\n",
        "    print(f'Average {metric_func.__name__} value for all genes: {avg_allTS}')\n",
        "\n",
        "  lowest_MAE = TS_combinations[avg_val.argmin()][0]\n",
        "  highest_MAE = TS_combinations[avg_val.argmax()][0]\n",
        "\n",
        "  if verbose:\n",
        "    print(f'Lowest time point: {lowest_MAE}')\n",
        "    print(f'Highest time point: {highest_MAE}')\n",
        "\n",
        "    print()\n",
        "  to_choose = [x for x in time_embeddings if x not in lowest_MAE]\n",
        "  print(f'Time Points to choose for further analysis: {to_choose}')\n",
        "\n",
        "  return avg_val, avg_allTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDSkAW8LAAfz"
      },
      "outputs": [],
      "source": [
        "avg_valarray_1, avg_val_1 = avg_metric_combinationTS(MAE, 1, hybrid_model, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKhXXcpQiMAg"
      },
      "outputs": [],
      "source": [
        "avg_valarray_2, avg_val_2 = avg_metric_combinationTS(MAE, 2, hybrid_model, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B51dKAII_d2w"
      },
      "outputs": [],
      "source": [
        "avg_valarray_3, avg_val_3 = avg_metric_combinationTS(MAE, 3, hybrid_model, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_OZ2vjo8653"
      },
      "outputs": [],
      "source": [
        "avg_valarray_4, avg_val_4 = avg_metric_combinationTS(MAE, 4, hybrid_model, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEiG0-3dpF05"
      },
      "outputs": [],
      "source": [
        "avg_valarray_5, avg_val_5 = avg_metric_combinationTS(MAE, 5, hybrid_model, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iBNl-TSYpGux"
      },
      "outputs": [],
      "source": [
        "avg_valarray_6, avg_val_6 = avg_metric_combinationTS(MAE, 6, hybrid_model, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pQZGqkIwmGDL"
      },
      "outputs": [],
      "source": [
        "# Plot Average MAE for all genes vs. number of shown time points\n",
        "plt.title(f\"No. time points shown vs. Average MAE\")\n",
        "plt.plot([1, 2, 3, 4, 5, 6], [avg_val_6, avg_val_5, avg_val_4, avg_val_3, avg_val_2, avg_val_1], color='blue')\n",
        "plt.xlabel('No. Shown Time Points')\n",
        "plt.ylabel('Average MAE for all genes')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "g_UozmwCr7_9"
      },
      "outputs": [],
      "source": [
        "def correlation_combination_timepoint(n, database=all_data, model=hybrid_model, verbose=False):\n",
        "  \"\"\"\n",
        "  correlation_combination_timepoint calculate correlation for prediction of combinations hidden time points for every gene in database\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  n\n",
        "      How many time points to mask\n",
        "  database\n",
        "      Database to choose genes from\n",
        "  model\n",
        "      Trained model to use\n",
        "  verbose\n",
        "      Print verbose output\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "    r_values\n",
        "      An array containing the average Pearson's r value for each combination of masked time points across all genes\n",
        "    avg_r2\n",
        "      The overall average R-squared value computed across all combinations and all genes\n",
        "  \"\"\"\n",
        "  model.eval()\n",
        "\n",
        "  combinations = generate_combintations(n)\n",
        "\n",
        "  r_values = []\n",
        "  r2_values = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for comb in combinations:\n",
        "      r_vals = 0\n",
        "      r2_vals = 0\n",
        "\n",
        "      seed = random.random()\n",
        "\n",
        "      for sequence in comb:\n",
        "        y_true_seq = np.zeros(len(bulks_adata.var))\n",
        "        y_pred_seq = np.zeros(len(bulks_adata.var))\n",
        "\n",
        "        for i in range(len(bulks_adata.var)):\n",
        "          formatted_input = database[i]\n",
        "\n",
        "          masked, y = mask(sequence, formatted_input)\n",
        "          masked, y = torch.tensor(masked, dtype=torch.float32), torch.tensor(y[0], dtype=torch.float32)\n",
        "\n",
        "          zeros_X = torch.nan_to_num(masked, nan=0.0, neginf=0.0)\n",
        "          _, prediction = model(zeros_X)\n",
        "\n",
        "          y_true_seq[i] = y.item()\n",
        "          y_pred_seq[i] = prediction.item()\n",
        "\n",
        "        r = scipy.stats.pearsonr(y_true_seq, y_pred_seq)[0]\n",
        "        r_vals += r\n",
        "        r2_vals += r**2\n",
        "\n",
        "      r_values.append(r_vals/len(comb))\n",
        "      r2_values.append(r2_vals/len(comb))\n",
        "\n",
        "\n",
        "      if verbose:\n",
        "        # print(f'R for time point(s) {comb[0]}: {r}')\n",
        "        print(f'R^2 for time point(s) {comb[0]}: {r**2}')\n",
        "        print()\n",
        "\n",
        "  r_values = np.array(r_values)\n",
        "  r2_values = np.array(r2_values)\n",
        "\n",
        "  avg_r2 = r2_values.sum()/len(r2_values)\n",
        "\n",
        "  if verbose: print(f'Average R^2: {avg_r2}')\n",
        "\n",
        "  return r_values, avg_r2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6er5EMsp1mpx"
      },
      "outputs": [],
      "source": [
        "r_vals_1, r_avg_1 = correlation_combination_timepoint(1, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "A67BF9yM4Ygi"
      },
      "outputs": [],
      "source": [
        "r_vals_2, r_avg_2 = correlation_combination_timepoint(2, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "V1vsuVnQ5AwB"
      },
      "outputs": [],
      "source": [
        "r_vals_3, r_avg_3 = correlation_combination_timepoint(3, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rteSZMm0-nJ_"
      },
      "outputs": [],
      "source": [
        "r_vals_4, r_avg_4 = correlation_combination_timepoint(4, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mErX34Sj-nVq"
      },
      "outputs": [],
      "source": [
        "r_vals_5, r_avg_5 = correlation_combination_timepoint(5, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BERit2XP-nqy"
      },
      "outputs": [],
      "source": [
        "r_vals_6, r_avg_6 = correlation_combination_timepoint(6, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aTfu9pQyVnhK"
      },
      "outputs": [],
      "source": [
        "# Plot Average R^2 for all genes vs. number of shown time points\n",
        "plt.title(f\"No. time points shown vs. Average R^2\")\n",
        "plt.plot([1, 2, 3, 4, 5, 6], [r_avg_6, r_avg_5, r_avg_4, r_avg_3, r_avg_2, r_avg_1], color='red')\n",
        "plt.xlabel('No. Shown Time Points')\n",
        "plt.ylabel('Average R^2 for all genes')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Single-cell performance analysis using scSemiProfiler"
      ],
      "metadata": {
        "id": "Api_QRlC6nwr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pdb,sys,os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import anndata\n",
        "import scanpy as sc\n",
        "sc.settings.verbosity = 0\n",
        "import argparse\n",
        "import copy\n",
        "import numpy as np\n",
        "import scipy\n",
        "import timeit\n",
        "\n",
        "from matplotlib.pyplot import figure\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Tuple\n",
        "import scSemiProfiler as semi\n",
        "from scSemiProfiler.utils import *\n",
        "name = 'single_cell_inference_project_lung_Alveolus_high'\n",
        "bulk = 'bulk_data_lung_Alveolus.h5ad'\n",
        "logged = False\n",
        "normed = False\n",
        "geneselection = False\n",
        "batch = 3\n",
        "\n",
        "t0 = anndata.read_h5ad(\"single_cell_inference_project_lung_Alveolus_high/sample_sc/t0.h5ad\")\n",
        "t1 = anndata.read_h5ad(\"single_cell_inference_project_lung_Alveolus_high/sample_sc/t1.h5ad\")\n",
        "t2 = anndata.read_h5ad(\"single_cell_inference_project_lung_Alveolus_high/sample_sc/t2.h5ad\")\n",
        "t3 = anndata.read_h5ad(\"single_cell_inference_project_lung_Alveolus_high/sample_sc/t3.h5ad\")\n",
        "t4 = anndata.read_h5ad(\"single_cell_inference_project_lung_Alveolus_high/sample_sc/t4.h5ad\")\n",
        "t5 = anndata.read_h5ad(\"single_cell_inference_project_lung_Alveolus_high/sample_sc/t5.h5ad\")\n",
        "t6 = anndata.read_h5ad(\"single_cell_inference_project_lung_Alveolus_high/sample_sc/t6.h5ad\")\n"
      ],
      "metadata": {
        "id": "0wPItPXHhKg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pdb, sys, os\n",
        "import anndata\n",
        "import scanpy as sc\n",
        "import argparse\n",
        "import copy\n",
        "import numpy as np\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from typing import Union\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def initsetup(name: str, bulk: str, logged: bool = False, normed: bool = True,\n",
        "              geneselection: Union[bool, int] = True, representatives: list = None) -> None:\n",
        "    \"\"\"\n",
        "    Initial setup of the semi-profiling pipeline, processing the bulk data,\n",
        "    and assigning each sample to the nearest fixed representative.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    name : str\n",
        "        Project name.\n",
        "    bulk : str\n",
        "        Path to bulk data as an h5ad file.\n",
        "    logged : bool\n",
        "        Whether the data has been logged or not.\n",
        "    normed : bool\n",
        "        Whether the library size has been normalized or not.\n",
        "    geneselection : bool or int\n",
        "        Perform gene selection (boolean) or specify number of highly variable genes.\n",
        "    representatives : list\n",
        "        Indices of fixed representative samples.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    None\n",
        "\n",
        "    Example\n",
        "    -------\n",
        "    >>> name = 'runexample'\n",
        "    >>> bulk = 'example_data/bulkdata.h5ad'\n",
        "    >>> logged = False\n",
        "    >>> normed = True\n",
        "    >>> geneselection = False\n",
        "    >>> representatives = [0, 2, 5]  # Fixed representative indices\n",
        "    >>> initsetup(name, bulk, logged, normed, geneselection, representatives)\n",
        "    \"\"\"\n",
        "\n",
        "    print('Start initial setup')\n",
        "\n",
        "    if not os.path.isdir(name):\n",
        "        os.system('mkdir ' + name)\n",
        "    else:\n",
        "        print(name + ' exists. Please choose another name.')\n",
        "        return\n",
        "\n",
        "    if not os.path.isdir(name + '/figures'):\n",
        "        os.system('mkdir ' + name + '/figures')\n",
        "\n",
        "    bulkdata = anndata.read_h5ad(bulk)\n",
        "\n",
        "    if not normed:\n",
        "        if logged:\n",
        "            print('Bad data preprocessing. Normalize library size before log-transformation.')\n",
        "            return\n",
        "        sc.pp.normalize_total(bulkdata, target_sum=1e4)\n",
        "\n",
        "    if not logged:\n",
        "        sc.pp.log1p(bulkdata)\n",
        "\n",
        "    sids = list(bulkdata.obs['sample_ids'])\n",
        "    with open(name + '/sids.txt', 'w') as f:\n",
        "        for sid in sids:\n",
        "            f.write(sid + '\\n')\n",
        "\n",
        "    if geneselection is False:\n",
        "        hvgenes = np.array(bulkdata.var.index)\n",
        "    elif geneselection is True:\n",
        "        sc.pp.highly_variable_genes(bulkdata, n_top_genes=6000)\n",
        "        bulkdata = bulkdata[:, bulkdata.var.highly_variable]\n",
        "        hvgenes = np.array(bulkdata.var.index)[bulkdata.var.highly_variable]\n",
        "    else:\n",
        "        sc.pp.highly_variable_genes(bulkdata, n_top_genes=int(geneselection))\n",
        "        bulkdata = bulkdata[:, bulkdata.var.highly_variable]\n",
        "        hvgenes = np.array(bulkdata.var.index)[bulkdata.var.highly_variable]\n",
        "    np.save(name + '/hvgenes.npy', hvgenes)\n",
        "\n",
        "    n_comps = min(100, bulkdata.X.shape[0] - 1)\n",
        "    sc.tl.pca(bulkdata, n_comps=n_comps)\n",
        "\n",
        "    bulkdata.write(name + '/processed_bulkdata.h5ad')\n",
        "\n",
        "    if representatives is None or len(representatives) == 0:\n",
        "        print(\"Please provide fixed representative indices.\")\n",
        "        return\n",
        "\n",
        "    representatives_pca = bulkdata.obsm['X_pca'][representatives]\n",
        "    distances = pairwise_distances(bulkdata.obsm['X_pca'], representatives_pca)\n",
        "    cluster_labels = np.argmin(distances, axis=1)\n",
        "\n",
        "    # Store the cluster labels\n",
        "    if not os.path.isdir(name + '/status'):\n",
        "        os.system('mkdir ' + name + '/status')\n",
        "\n",
        "    with open(name + '/status/init_cluster_labels.txt', 'w') as f:\n",
        "        for label in cluster_labels:\n",
        "            f.write(str(label) + '\\n')\n",
        "\n",
        "    with open(name + '/status/init_representatives.txt', 'w') as f:\n",
        "        for rep in representatives:\n",
        "            f.write(str(rep) + '\\n')\n",
        "\n",
        "    print('Initial setup finished. Among ' + str(len(sids)) +\n",
        "          ' total samples, assigned to fixed representatives:')\n",
        "    for i, rep in enumerate(representatives):\n",
        "        print(f\"Cluster {i} representative: {sids[rep]}\")\n",
        "\n",
        "    return"
      ],
      "metadata": {
        "id": "NeImJMf4h5gX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initsetup(name,bulk,logged=logged,normed=normed,geneselection=True,representatives=[0,3,6])"
      ],
      "metadata": {
        "id": "PYTjY7LJhLob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import anndata as ad\n",
        "import hdf5plugin\n",
        "\n",
        "reps_processed = ad.concat([t0, t3,t6], axis=0, join='inner')\n",
        "\n",
        "print(f\"Number of observations (cells): {reps_processed.n_obs}\")\n",
        "print(f\"Number of variables (genes): {reps_processed.n_vars}\")\n",
        "\n",
        "if 'cell_id' not in reps_processed.obs.columns:\n",
        "    reps_processed.obs['cell_id'] = reps_processed.obs_names\n",
        "\n",
        "if 'n_genes' not in reps_processed.obs.columns:\n",
        "    reps_processed.obs['n_genes'] = (reps_processed.X > 0).sum(axis=1)\n",
        "\n",
        "\n",
        "if 'gene_ids' not in reps_processed.var.columns:\n",
        "    reps_processed.var['gene_ids'] = reps_processed.var_names\n",
        "\n",
        "\n",
        "reps_processed.obs.columns = reps_processed.obs.columns.astype(str)\n",
        "reps_processed.var.columns = reps_processed.var.columns.astype(str)\n",
        "\n",
        "# Convert object dtype columns in obs and var to strings\n",
        "for col in reps_processed.obs.columns:\n",
        "    if reps_processed.obs[col].dtype == 'object':\n",
        "        reps_processed.obs[col] = reps_processed.obs[col].astype(str)\n",
        "\n",
        "for col in reps_processed.var.columns:\n",
        "    if reps_processed.var[col].dtype == 'object':\n",
        "        reps_processed.var[col] = reps_processed.var[col].astype(str)\n",
        "\n",
        "print(\"Data types in obs:\")\n",
        "print(reps_processed.obs.dtypes)\n",
        "print(\"Data types in var:\")\n",
        "print(reps_processed.var.dtypes)\n",
        "import numpy as np\n",
        "\n",
        "hvgenes = np.load(name + '/hvgenes.npy', allow_pickle=True)\n",
        "\n",
        "print(\"First few genes in hvgenes:\", hvgenes[:5])\n",
        "\n",
        "reps_genes = reps_processed.var_names\n",
        "\n",
        "common_genes = np.intersect1d(hvgenes, reps_genes)\n",
        "\n",
        "print(f\"Number of genes in hvgenes: {len(hvgenes)}\")\n",
        "print(f\"Number of genes in reps_processed: {len(reps_genes)}\")\n",
        "print(f\"Number of common genes: {len(common_genes)}\")\n",
        "\n",
        "missing_in_reps = np.setdiff1d(hvgenes, reps_genes)\n",
        "print(f\"Number of genes in hvgenes not in reps_processed: {len(missing_in_reps)}\")\n",
        "\n",
        "hvgenes_in_reps_ordered = [gene for gene in hvgenes if gene in reps_genes]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "reps_filtered = reps_processed[:, hvgenes_in_reps_ordered].copy()\n",
        "\n",
        "\n",
        "assert all(reps_filtered.var_names == hvgenes_in_reps_ordered), \"Gene order does not match!\"\n",
        "\n"
      ],
      "metadata": {
        "id": "m3j6ZrMFiXdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reps_filtered.write_h5ad(\n",
        "      name+'/representative_sc.h5ad',\n",
        "      compression=hdf5plugin.FILTERS[\"zstd\"]\n",
        "    )"
      ],
      "metadata": {
        "id": "Cdjr7cOgiayU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# start single cell processing\n",
        "semi.scprocess(name=name,singlecell=name+'/representative_sc.h5ad',normed=True,logged=False,cellfilter=False,threshold=1e-3,geneset=True,weight=0.5,k=15)\n"
      ],
      "metadata": {
        "id": "NxXq4Taqim7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read the representatives and clusterings\n",
        "sids = []\n",
        "f = open(name + '/sids.txt','r')\n",
        "lines = f.readlines()\n",
        "for l in lines:\n",
        "    sids.append(l.strip())\n",
        "f.close()\n",
        "\n",
        "repres = []\n",
        "f=open(name + '/status/init_representatives.txt','r')\n",
        "lines = f.readlines()\n",
        "f.close()\n",
        "for l in lines:\n",
        "    repres.append(int(l.strip()))\n",
        "\n",
        "cl = []\n",
        "f=open(name + '/status/init_cluster_labels.txt','r')\n",
        "lines = f.readlines()\n",
        "f.close()\n",
        "for l in lines:\n",
        "    cl.append(int(l.strip()))\n",
        "\n",
        "print('representatives:',repres)\n",
        "print('cluster labels:',cl)"
      ],
      "metadata": {
        "id": "cCakSYnbipBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "representatives = name + '/status/init_representatives.txt'\n",
        "cluster = name + '/status/init_cluster_labels.txt'\n",
        "\n",
        "bulktype = 'pseudobulk'\n",
        "semi.scinfer(name, representatives,cluster,bulktype, device='cuda:0')"
      ],
      "metadata": {
        "id": "ll7MaWmnivIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_labels = cl\n",
        "semisdata = assemble_cohort(name,\n",
        "                repres,\n",
        "                cl,\n",
        "                celltype_key = 'celltype',\n",
        "                sample_info_keys = ['sample_ids'],\n",
        "                bulkpath= 'bulk_data_lung_Alveolus.h5ad')"
      ],
      "metadata": {
        "id": "DXPNmeZYi5WU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read the combined adata of gound true single cell data for subsequent comparison\n",
        "combined_adata = anndata.read_h5ad(name+\"/combined_data.h5ad\")\n"
      ],
      "metadata": {
        "id": "StRbQ3dci7cu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#filter out NA celltypes\n",
        "import pandas as pd\n",
        "\n",
        "invalid_values = [None, pd.NA, float('nan'), 'nan', 'NA']\n",
        "\n",
        "def filter_invalid_celltypes(adata):\n",
        "    return adata[~adata.obs['celltype'].astype(str).str.strip().isin(invalid_values)].copy()\n",
        "\n",
        "combined_adata = filter_invalid_celltypes(combined_adata)\n",
        "semisdata = filter_invalid_celltypes(semisdata)\n",
        "\n",
        "print(f\"Filtered combined_adata cells: {combined_adata.n_obs}\")\n",
        "print(f\"Filtered semisdata cells: {semisdata.n_obs}\")\n",
        "\n",
        "combined_adata.write_h5ad('combined_adata_filtered.h5ad')\n",
        "semisdata.write_h5ad('semisdata_filtered.h5ad')\n"
      ],
      "metadata": {
        "id": "xpbobmy5jAiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize distribution of assembled ground truth data and semi-profiled data\n",
        "combined_data,gtdata,semidata = compare_umaps(\n",
        "            semidata = semisdata,\n",
        "            gtdata = combined_adata,\n",
        "            name = name,\n",
        "            representatives = name + '/status/init_representatives.txt',\n",
        "            cluster_labels = name + '/status/init_cluster_labels.txt',\n",
        "            celltype_key = 'celltype',\n",
        "            save = name+\"/figures\"\n",
        "            )"
      ],
      "metadata": {
        "id": "Wy7F0bLJjYvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def composition_by_group(\n",
        "    adata: anndata.AnnData,\n",
        "    colormap: Union[str, list] = None,\n",
        "    groupby: str = None,\n",
        "    title: str = 'Cell type composition',\n",
        "    save: str = None,\n",
        "    name: str = None\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Visualizing the cell type composition in each group.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    adata:\n",
        "        The dataset to investigate.\n",
        "    colormap:\n",
        "        The colormap for visualization.\n",
        "    groupby:\n",
        "        The key in .obs specifying groups.\n",
        "    title:\n",
        "        Plot title.\n",
        "    save:\n",
        "        Path to save the plot as a PDF file.\n",
        "    name:\n",
        "        Folder to save the file in, if provided.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "        None\n",
        "\n",
        "    Example\n",
        "    -------\n",
        "    >>> groupby = 'states_collection_sum'\n",
        "    >>> composition_by_group2(\n",
        "    >>>     adata=gtdata,\n",
        "    >>>     groupby=groupby,\n",
        "    >>>     title='Ground truth'\n",
        "    >>> )\n",
        "    \"\"\"\n",
        "    totaltypes = np.array(adata.obs['celltype'].cat.categories)\n",
        "\n",
        "    if colormap is None:\n",
        "        colormap = adata.uns['celltypes_colors']\n",
        "\n",
        "    conditions = np.unique(adata.obs[groupby])\n",
        "    n = conditions.shape[0]\n",
        "    percentages = []\n",
        "\n",
        "    for i in range(conditions.shape[0]):\n",
        "        condition_prop = celltype_proportion(adata[adata.obs[groupby] == conditions[i]], totaltypes)\n",
        "        percentages.append(condition_prop)\n",
        "\n",
        "    fig, axs = plt.subplots(n, 1, figsize=(n, 1))\n",
        "    axs[0].set_title(title)\n",
        "\n",
        "    for j in range(n):\n",
        "        for i in range(len(totaltypes)):\n",
        "            axs[j].barh(conditions[j], percentages[j][i], left=sum(percentages[j][:i]), color=colormap[i])\n",
        "            axs[j].set_xlim([0, 1])\n",
        "            axs[j].set_yticklabels([])\n",
        "            axs[j].yaxis.set_tick_params(left=False, right=False, labelleft=False, labelbottom=False, bottom=False)\n",
        "\n",
        "            if j != n:\n",
        "                axs[j].set_xticklabels([])\n",
        "\n",
        "        axs[j].text(-0.01, 0, conditions[j], ha='right', va='center')\n",
        "\n",
        "    patches = [mpatches.Patch(color=colormap[i], label=totaltypes[i]) for i in range(len(totaltypes))]\n",
        "    axs[-1].legend(handles=patches, loc='center left', bbox_to_anchor=(1.1, n))\n",
        "\n",
        "    plt.xlabel('Proportion')\n",
        "\n",
        "    if save is not None:\n",
        "        save_path = f\"{name}/{save}.pdf\" if name else f\"{save}.pdf\"\n",
        "        plt.savefig(save_path, format='pdf', dpi=600, bbox_inches='tight')\n",
        "\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "sDaszp25jj0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize cell types composition by timepoints\n",
        "groupby = 'sample_ids'\n",
        "composition_by_group(\n",
        "    adata = combined_adata,\n",
        "    groupby = groupby,\n",
        "    title = 'Ground truth',\n",
        "    colormap = semidata.uns['celltype_colors'],\n",
        "    save = \"/composition_gt\",\n",
        "    name = name\n",
        "    )"
      ],
      "metadata": {
        "id": "-DeHuzRRjosl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enrichment_comparison(name, combined_adata, semisdata, celltype_key = 'celltype', selectedtype = \"AT1\", save = \"figures\")\n"
      ],
      "metadata": {
        "id": "dacQQrIcj0pt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def enrichment_comparison_reactome(name:str,\n",
        "                                   gtdata:anndata.AnnData,\n",
        "                                   semisdata:anndata.AnnData,\n",
        "                                   celltype_key:str,\n",
        "                                   selectedtype:str,\n",
        "                                   save = None\n",
        "                                  ) -> Tuple[np.array, np.array, np.array, np.array]:\n",
        "    \"\"\"\n",
        "    Compare the enrichment analysis results using the real-profiled and semi-profiled datasets, using Reactome pathway sets.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    name:\n",
        "        Project name\n",
        "    gtdata:\n",
        "        Real-profiled (ground truth) data (AnnData object)\n",
        "    semisdata:\n",
        "        Semi-profiled dataset (AnnData object)\n",
        "    celltype_key:\n",
        "        The key in anndata.AnnData.obs that stores cell type information\n",
        "    selectedtype:\n",
        "        The selected cell type to analyze\n",
        "    save:\n",
        "        Path within the 'figures' folder to save the plot\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    CommonDEGs : int\n",
        "        The number of overlapping DEGs between real and semi-profiled data\n",
        "    HypergeometricP : float\n",
        "        P-value of hypergeometric test examining the overlap between two versions of DEGs\n",
        "    PearsonR : float\n",
        "        Pearson correlation between bar lengths in real-profiled and semi-profiled bar plots\n",
        "    PearsonP : float\n",
        "        P-value of the Pearson correlation test\n",
        "\n",
        "    Example\n",
        "    -------\n",
        "    >>> _ = enrichment_comparison_reactome(name, gtdata, semisdata, celltype_key='celltypes', selectedtype='CD4')\n",
        "    \"\"\"\n",
        "\n",
        "    totaltypes = np.unique(gtdata.obs[celltype_key])\n",
        "\n",
        "    sc.tl.rank_genes_groups(gtdata, celltype_key, method='t-test')\n",
        "    typededic = {}\n",
        "    for j in range(totaltypes.shape[0]):\n",
        "        celltype = totaltypes[j]\n",
        "        typede = []\n",
        "        for i in range(100):\n",
        "            g = gtdata.uns['rank_genes_groups']['names'][i][j]\n",
        "            typede.append(g)\n",
        "        typededic[celltype] = typede\n",
        "\n",
        "    sc.tl.rank_genes_groups(semisdata, celltype_key, method='t-test')\n",
        "    semitypededic = {}\n",
        "    for j in range(totaltypes.shape[0]):\n",
        "        celltype = totaltypes[j]\n",
        "        typede = []\n",
        "        for i in range(100):\n",
        "            g = semisdata.uns['rank_genes_groups']['names'][i][j]\n",
        "            typede.append(g)\n",
        "        semitypededic[celltype] = typede\n",
        "\n",
        "    gtdeg = typededic[selectedtype]\n",
        "    semideg = semitypededic[selectedtype]\n",
        "    c = sum([1 for i in semideg if i in gtdeg])\n",
        "\n",
        "    hyperpval = hypert(semisdata.X.shape[1], 100, 100, c)\n",
        "    print('p-value of hypergeometric test for overlapping DEGs:', str(float(hyperpval)))\n",
        "\n",
        "    if (os.path.isdir(name + '/gseapygt')) == False:\n",
        "        os.system('mkdir ' + name + '/gseapygt')\n",
        "    if (os.path.isdir(name + '/gseapysemi')) == False:\n",
        "        os.system('mkdir ' + name + '/gseapysemi')\n",
        "\n",
        "    results = gseapy.enrichr(gene_list=gtdeg, gene_sets='Reactome_2022', outdir=name + '/gseapygt')\n",
        "    f = open(name + '/gseapygt/Reactome_2022.human.enrichr.reports.txt', 'r')\n",
        "    lines = f.readlines()\n",
        "    f.close()\n",
        "\n",
        "    gtsets = []\n",
        "    gtps = []\n",
        "    gtdic = {}\n",
        "    for l in lines[1:]:\n",
        "        term = l.split('\\t')[1]\n",
        "        p = float(l.split('\\t')[4])\n",
        "        gtsets.append(term)\n",
        "        gtps.append(p)\n",
        "        gtdic[term] = p\n",
        "\n",
        "    results = gseapy.enrichr(gene_list=semideg, gene_sets='Reactome_2022', outdir=name + '/gseapysemi')\n",
        "    f = open(name + '/gseapysemi/Reactome_2022.human.enrichr.reports.txt','r')\n",
        "    lines = f.readlines()\n",
        "    f.close()\n",
        "\n",
        "    semisets = []\n",
        "    semips = []\n",
        "    semidic = {}\n",
        "    for l in lines[1:]:\n",
        "        term = l.split('\\t')[1]\n",
        "        p = float(l.split('\\t')[4])\n",
        "        semisets.append(term)\n",
        "        semips.append(p)\n",
        "        semidic[term] = p\n",
        "\n",
        "    terms = copy.deepcopy(gtsets[:10])\n",
        "    real_data = copy.deepcopy(gtps[:10])\n",
        "    sim_data = []\n",
        "    for i in range(10):\n",
        "        gtterm = semisets[i]\n",
        "        if gtterm not in semidic.keys():\n",
        "            sim_data.append(1)\n",
        "        else:\n",
        "            sim_data.append(semidic[gtterm])\n",
        "\n",
        "    for i in range(10):\n",
        "        if semisets[i] in terms:\n",
        "            continue\n",
        "        terms.append(semisets[i])\n",
        "        sim_data.append(semips[i])\n",
        "        if semisets[i] not in gtdic.keys():\n",
        "            real_data.append(1)\n",
        "        else:\n",
        "            real_data.append(gtdic[semisets[i]])\n",
        "\n",
        "    real_data = np.flip(real_data)\n",
        "    sim_data = np.flip(sim_data)\n",
        "    terms = np.flip(terms)\n",
        "    sim_bar_lengths = [-np.log10(p) for p in sim_data]\n",
        "    real_bar_lengths = [-np.log10(p) for p in real_data]\n",
        "\n",
        "    res = scipy.stats.pearsonr(np.array(sim_bar_lengths), np.array(real_bar_lengths))\n",
        "    print('Significance correlation:', res)\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(8, 5))\n",
        "    bar_width = 0.4\n",
        "    y = np.arange(len(sim_data)) + 1\n",
        "    ax1.barh(y, real_bar_lengths, height=bar_width, color='green', label='Real')\n",
        "    ax1.set_xlabel('-log10(p)')\n",
        "    ax1.set_ylabel('Term')\n",
        "    ax1.set_title('Real Data (' + str(len(semideg)) + ' DEGs)')\n",
        "    ax2.barh(y, sim_bar_lengths, height=bar_width, color='blue', label='Simulated')\n",
        "    ax2.set_xlabel('-log10(p)')\n",
        "    ax2.set_title('Semi-profiled Data(' + str(len(gtdeg)) + ' DEGs)')\n",
        "\n",
        "    max_val = max(max(sim_bar_lengths), max(real_bar_lengths))\n",
        "    ax1.set_xlim(0, max_val + 1)\n",
        "    ax2.set_xlim(0, max_val + 1)\n",
        "    ax1.invert_xaxis()\n",
        "    ax1.set_yticks(y)\n",
        "    ax2.set_yticklabels(terms)\n",
        "    fig.suptitle(selectedtype + ' Reactome (' + str(c) + ' Overlap DEGs)')\n",
        "\n",
        "    if save is not None:\n",
        "        plt.savefig(name + '/figures/' + save + selectedtype + ' Reactome.pdf', bbox_inches='tight')\n",
        "        plt.savefig(name + '/figures/' + save + selectedtype + ' Reactome.jpg', dpi=600, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    return c, float(hyperpval), res[0], res[1]\n"
      ],
      "metadata": {
        "id": "Kl1xvn4LkAPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enrichment_comparison_reactome(name, combined_adata, semisdata, celltype_key = 'celltype', selectedtype = \"AT1\", save = \"figures\")\n"
      ],
      "metadata": {
        "id": "uSFhQWfrkFEo"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "KEeVKIxr83FW",
        "Obrg0jI4jTEQ",
        "-hQlEDawFT7-",
        "3UQs7CaW6f59",
        "Api_QRlC6nwr"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}